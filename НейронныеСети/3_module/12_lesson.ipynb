{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Современные архитектуры\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как устроены современные архитектуры свёрточных сетей.\n",
    "\n",
    "Вспомним про задачу ImageNet. Люди за много лет насобирали более миллиона изображений, которые размечены на 1 000 классов. Классы довольно сложные (например, разные породы собак и кошек). Для неподготовленного человека разделить эти изображения на классы достаточно сложно.\n",
    "\n",
    "В 2012 году решению этой задачи обучили огромную нейросеть AlexNet.\n",
    "\n",
    "Устроена она была так: у нас есть несколько свёрточных слоев с макс-пулингом между ними и мы используем свертки 11 × 11, 5 × 5, 3 × 3.\n",
    "\n",
    "Дополнительно использовался dropout, аугментация данных и ReLu (специальная функция активации). Про них узнаем в следующем модуле, а сейчас посмотрим вот на что: в этой сети было 60 миллионов параметров и это была беспрецедентная сеть на тот момент.\n",
    "\n",
    "Про аугментацию данных — один из трюков нейросети AlexNet можем поговорить уже сейчас.\n",
    "\n",
    "В нейросети было 60 миллионов параметров, которые нужно оценить по миллиону изображений. На самом деле картинок слишком мало, чтобы оценить столько параметров. Попробуем слегка видоизменить картинки (повернуть, отразить, растянуть, поменять резкость) и тогда наши данные для обучения увеличатся. Все эти манипуляции с картинками и называются аугментацией данных.\n",
    "\n",
    "Стоит отметить, что добавлять сдвиги при аугментации данных бесполезно.\n",
    "\n",
    "Можно было бы предположить, что сдвиги помогут нам научится искать котов на разных положениях на картинке, но нам это не нужно, если у нас есть макс-пулинг слой, ведь достаточно просто сделать архитектуру таким образом, чтобы где-то близко к выходному слою мы взяли максимум.\n",
    "\n",
    "Другой пример архитектуры — VGG, предложенная в 2015 году. Спустя 3 года после AlexNet. Видеокарты к тому времени стали мощнее и новая сеть содержала 138 миллионов параметров. Здесь уже не использовали дорогие и тяжелые свёртки размера 11 × 11, а обошлись большим числом сверток размером 3 × 3. В остальном по принципу нейросеть очень похожа на AlexNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
