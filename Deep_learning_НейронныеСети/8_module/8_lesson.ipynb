{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Оптимальная политика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Политика — это отображение состояния в действие. Политика может быть задана стохастически. Мы будем рассматривать детерминированный случай, когда с вероятностью 100 % по состоянию будем выбирать действие."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lms-cdn.skillfactory.ru/assets/courseware/v1/606b4cc5d67fc0c33aa2672aaec71e2b/asset-v1:SkillFactory+MLDL+ALWAYS+type@asset+block/DL_11_модуль_9.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Траектория — это цепочка: состояние, действие, награда, состояние, действие, награда, состояние ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lms-cdn.skillfactory.ru/assets/courseware/v1/52c15d060213e99709473d942ff5bda5/asset-v1:SkillFactory+MLDL+ALWAYS+type@asset+block/DL_11_модуль_10.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Суммарная награда — сумма всех наград, полученных по траектории."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lms-cdn.skillfactory.ru/assets/courseware/v1/ebf2fcec306d31a5e7cfc349d4dd04b6/asset-v1:SkillFactory+MLDL+ALWAYS+type@asset+block/DL_11_модуль_11.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель — найти политику, при которой суммарная награда будет максимальной.\n",
    "\n",
    "В обучении с подкреплением обычно используется модификация суммарной награды — дисконтированная суммарная награда. Идея её состоит в том, что награда, которая придёт на ближайших этапах, важнее. Задаётся дисконтированная награда с помощью геометрического взвешивания действий, каждой награде присваивается вес γt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lms-cdn.skillfactory.ru/assets/courseware/v1/7510af84c35ecbd1c03a1f54af3e55e8/asset-v1:SkillFactory+MLDL+ALWAYS+type@asset+block/DL_11_модуль_12.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формальная задача в обучении с подкреплением — максимизация дисконтированной награды. Далее мы будем работать именно с дисконтированной суммарной наградой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lms-cdn.skillfactory.ru/assets/courseware/v1/8f9aecb5f1f9b06ab596546f20d6485f/asset-v1:SkillFactory+MLDL+ALWAYS+type@asset+block/DL_11_модуль_16.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В стохастическом случае используется математическое ожидание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lms-cdn.skillfactory.ru/assets/courseware/v1/3d7e3cf7b83733e15d2b7de0b1d5b5a7/asset-v1:SkillFactory+MLDL+ALWAYS+type@asset+block/DL_11_модуль_17.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
