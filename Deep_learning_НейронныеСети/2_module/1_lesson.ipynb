{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом модуле мы разберемся с фреймворком для нейросетей TensorFlow, посмотрим на детали того, что происходит «под капотом», и какие API есть для нас.\n",
    "\n",
    "Линейная классификация\n",
    "\n",
    "Представьте, что у нас есть признаки x = (x1, x2) и есть выборка положительных и отрицательных точек y ∈ {+1, −1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lms-cdn.skillfactory.ru/assets/courseware/v1/301f1b273f5daf380360132ff37d12b0/asset-v1:SkillFactory+MLDL+ALWAYS+type@asset+block/sl1_1.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам нужно найти разделяющую гиперплоскость между ними. В данном случае это просто линия. Линия задается тремя коэффициентами:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lms-cdn.skillfactory.ru/assets/courseware/v1/0e05eb6c69b6512958ad3b6f47557ec2/asset-v1:SkillFactory+MLDL+ALWAYS+type@asset+block/fun1.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам нужно найти три коэффициента w, которые зададут линию. Далее мы можем взять точку х и понять, где она находится относительно линии: выше или ниже. Для этого нам нужно узнать знак линейной комбинации. Вектор весов w задаёт нормаль к нашей линии, то есть он перпендикулярен ей (фиолетовый вектор на графике ниже).\n",
    "\n",
    "Линейная комбинация — это скалярное произведение и длина проекции какого-нибудь другого вектора на наш вектор w."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lms-cdn.skillfactory.ru/assets/courseware/v1/d61b08d27dbc194755fc29e3bf7ac3b8/asset-v1:SkillFactory+MLDL+ALWAYS+type@asset+block/sl1_2.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому проекция становится разных знаков. Из этих соображений мы делаем линейный классификатор. Наш алгоритм: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lms-cdn.skillfactory.ru/assets/courseware/v1/1df4fa0464eec3b489eb21484103556a/asset-v1:SkillFactory+MLDL+ALWAYS+type@asset+block/fun21.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь появляется знак нашей линейной комбинации. Настроить линейный классификатор — значит, найти эти коэффициенты. \n",
    "\n",
    "Логистическая регрессия\n",
    "\n",
    "Она тоже решает задачу классификации, но в конце применяется не функция знака, а сигмоидная функция. Она превращает длину проекции в уверенность.\n",
    "\n",
    "Уверенность и неуверенность появляется из-за краевых эффектов: на границе классов может быть какой-то шум, и в классификации точек, которые находятся рядом с красной разделяющей линией, мы не очень уверены. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lms-cdn.skillfactory.ru/assets/courseware/v1/c0fbb0c94cf7c2140fa72fc284e54e60/asset-v1:SkillFactory+MLDL+ALWAYS+type@asset+block/sl2_0.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А если мы уходим далеко от линии вглубь классов, то предполагается, что мы более уверены в этом предсказании. Сигмоида делает именно это — превращает длину проекции линейной комбинации в уверенность.\n",
    "\n",
    "Сигмоида устроена не случайным образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lms-cdn.skillfactory.ru/assets/courseware/v1/59e61439b38334fc16ff4da30829a8e3/asset-v1:SkillFactory+MLDL+ALWAYS+type@asset+block/sl2_2.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если длина проекции 0 (точка ровно на красной линии) , то сигмоида дает 0,5. Логистическая регрессия предсказывает вероятность положительного класса. Вероятность отрицательного будет единица минус предсказанная вероятность положительного класса. \n",
    "\n",
    "Другой пример\n",
    "\n",
    "Представим, что у нас есть следующая задача:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lms-cdn.skillfactory.ru/assets/courseware/v1/3a096f1287913d671c9dd92fcd460f37/asset-v1:SkillFactory+MLDL+ALWAYS+type@asset+block/sl3.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы решить подобную задачу, мы можем «подпереть» треугольник тремя линиями и сделать алгоритм, используя только логистическую регрессию.\n",
    "\n",
    "Для начала мы отделим минусы слева и построим логистическую регрессию:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lms-cdn.skillfactory.ru/assets/courseware/v1/4cacc2ddf570400e4e9356a346b6ef49/asset-v1:SkillFactory+MLDL+ALWAYS+type@asset+block/sl4.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти данные подадим для обучения логистической регрессии и получим коэффициенты красной линии. \n",
    "\n",
    "Отделим остальные минусы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lms-cdn.skillfactory.ru/assets/courseware/v1/5a47e1c994534185bab53e6a10466aa1/asset-v1:SkillFactory+MLDL+ALWAYS+type@asset+block/sl5.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все коэффициенты мы получили практически вручную. Сейчас у нас есть коэффициенты трёх логистических регрессий, каждая из которых решает свою маленькую подзадачу. \n",
    "\n",
    "Теперь возьмём какую-нибудь точку и посмотрим, какие три предсказания дают эти линии в точке:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lms-cdn.skillfactory.ru/assets/courseware/v1/80ebfdc4bec430d912c56930b6467065/asset-v1:SkillFactory+MLDL+ALWAYS+type@asset+block/sl6.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что делать с этими тремя значениями?\n",
    "\n",
    "В координатах х1 и х2 эта задача не решается. Поэтому полученные коэффициенты мы можем рассматривать как новые координаты. \n",
    "\n",
    "Получим три признака, каждый из которых говорит, где мы находимся относительно каждой стороны треугольника. \n",
    "\n",
    "Давайте возьмём наш целевой признак y, добавим его в нашу новую таблицу, где наши новые признаки с предсказаниями, и попробуем решить её с новыми признаками с помощью линейной логистической регрессии. На новой выборке получим логистическую регрессию:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lms-cdn.skillfactory.ru/assets/courseware/v1/ea26d51daa8fcd16594b1c67bd77302e/asset-v1:SkillFactory+MLDL+ALWAYS+type@asset+block/sl7.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь она дает нам некоторые коэффициенты и взвешивает уже не признаки, а предсказания. То, что мы получили — простейшая нейросеть. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
