{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import surprise\n",
    "import apyori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
      "Done! Dataset ml-100k has been saved to /Users/apple/.surprise_data/ml-100k\n"
     ]
    }
   ],
   "source": [
    "data = surprise.Dataset.load_builtin(\"ml-100k\")\n",
    "trainingSet = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet = trainingSet.build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пользователей в trainingSet: 943\n"
     ]
    }
   ],
   "source": [
    "data = surprise.Dataset.load_builtin(\"ml-100k\")\n",
    "trainingSet = data.build_full_trainset()\n",
    "num_users = trainingSet.n_users\n",
    "print(f\"Количество пользователей в trainingSet: {num_users}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_items = trainingSet.n_items\n",
    "num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "KNNBasic: Пользователь 521 -> Рекомендованный фильм 246\n",
      "SVD: Пользователь 521 -> Рекомендованный фильм 246\n",
      "ID рекомендованного фильма (KNNBasic): 246\n",
      "ID рекомендованного фильма (SVD): 246\n",
      "Лучшее значение RMSE: 0.94\n"
     ]
    }
   ],
   "source": [
    "import surprise\n",
    "from surprise import KNNBasic, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Тренировка модели KNNBasic\n",
    "algo_knn = KNNBasic()\n",
    "algo_knn.fit(trainset)\n",
    "\n",
    "# Тренировка модели SVD\n",
    "algo_svd = SVD()\n",
    "algo_svd.fit(trainset)\n",
    "\n",
    "# Предсказания на тестовом наборе для обеих моделей\n",
    "predictions_knn = algo_knn.test(testset)\n",
    "predictions_svd = algo_svd.test(testset)\n",
    "\n",
    "# Индекс, для которого мы хотим получить предсказание\n",
    "index = 8  # Замените на нужный индекс\n",
    "\n",
    "# Получение предсказания под -ым индексом\n",
    "pred_knn = predictions_knn[index]\n",
    "pred_svd = predictions_svd[index]\n",
    "\n",
    "# Вывод информации о предсказаниях\n",
    "print(f\"KNNBasic: Пользователь {pred_knn.uid} -> Рекомендованный фильм {pred_knn.iid}\")\n",
    "print(f\"SVD: Пользователь {pred_svd.uid} -> Рекомендованный фильм {pred_svd.iid}\")\n",
    "\n",
    "# Вывод id рекомендованного фильма для KNNBasic\n",
    "print(f\"ID рекомендованного фильма (KNNBasic): {pred_knn.iid}\")\n",
    "\n",
    "# Вывод id рекомендованного фильма для SVD\n",
    "print(f\"ID рекомендованного фильма (SVD): {pred_svd.iid}\")\n",
    "# Предсказания на тестовом наборе для обеих моделей\n",
    "predictions_knn = algo_knn.test(testset)\n",
    "predictions_svd = algo_svd.test(testset)\n",
    "\n",
    "# Расчет RMSE для обеих моделей\n",
    "rmse_knn = accuracy.rmse(predictions_knn, verbose=False)\n",
    "rmse_svd = accuracy.rmse(predictions_svd, verbose=False)\n",
    "\n",
    "# Сравнение и выбор лучшего результата\n",
    "best_rmse = min(rmse_knn, rmse_svd)\n",
    "\n",
    "# Округление до двух знаков после точки\n",
    "best_rmse_rounded = round(best_rmse, 2)\n",
    "\n",
    "# Вывод RMSE для лучшего алгоритма\n",
    "print(f\"Лучшее значение RMSE: {best_rmse_rounded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id movie_id  rating          3\n",
       "0     196      242     3.0  881250949\n",
       "1     186      302     3.0  891717742\n",
       "2      22      377     1.0  878887116\n",
       "3     244       51     2.0  880606923\n",
       "4     166      346     1.0  886397596"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data.raw_ratings)\n",
    "df.columns = ['user_id', 'movie_id', 'rating', 3]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Строка для user_id 100: 4 435 153 310 258 319 887 211 325 202 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/07/56f70q6n70d3v657jsy7fjgr0000gn/T/ipykernel_61018/1049805414.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  user_100_movies = user_movie_strings.get(100, \"\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data.raw_ratings)\n",
    "df.columns = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "\n",
    "# Отфильтруем строки, где рейтинг >= 4\n",
    "df_filtered = df[df['rating'] >= 4]\n",
    "\n",
    "# Группируем по user_id и объединяем movie_id в строку с пробелом в качестве разделителя\n",
    "user_movie_strings = df_filtered.groupby('user_id')['movie_id'].apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "# Получаем строку для user_id 100\n",
    "user_100_movies = user_movie_strings.get(100, \"\")\n",
    "\n",
    "\n",
    "# Вывод результата\n",
    "print(f\"Строка для user_id 100: {user_100_movies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество ассоциативных правил: 10\n"
     ]
    }
   ],
   "source": [
    "import surprise\n",
    "import pandas as pd\n",
    "from apyori import apriori\n",
    "\n",
    "# Загрузка встроенного набора данных\n",
    "data = surprise.Dataset.load_builtin(\"ml-100k\")\n",
    "\n",
    "# Создаем DataFrame из raw_ratings\n",
    "df = pd.DataFrame(data.raw_ratings)\n",
    "df.columns = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "\n",
    "# Отфильтруем строки, где рейтинг >= 4\n",
    "df_filtered = df[df['rating'] >= 4]\n",
    "\n",
    "# Группируем фильмы по пользователям, формируя транзакции\n",
    "transactions = df_filtered.groupby('user_id')['movie_id'].apply(list).tolist()\n",
    "\n",
    "# Применение алгоритма Apriori с заданными параметрами\n",
    "rules = apriori(transactions, min_support=0.2, min_confidence=0.3, min_lift=2, min_length=2)\n",
    "\n",
    "# Преобразование результата в список\n",
    "rules_list = list(rules)\n",
    "\n",
    "# Подсчет количества правил\n",
    "num_rules = len(rules_list)\n",
    "\n",
    "# Вывод результата\n",
    "print(f\"Количество ассоциативных правил: {num_rules}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID фильма, который чаще всего встречается в правилах: 174\n"
     ]
    }
   ],
   "source": [
    "import surprise\n",
    "import pandas as pd\n",
    "from apyori import apriori\n",
    "from collections import Counter\n",
    "\n",
    "# Загрузка встроенного набора данных\n",
    "data = surprise.Dataset.load_builtin(\"ml-100k\")\n",
    "\n",
    "# Создаем DataFrame из raw_ratings\n",
    "df = pd.DataFrame(data.raw_ratings)\n",
    "df.columns = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "\n",
    "# Отфильтруем строки, где рейтинг >= 4\n",
    "df_filtered = df[df['rating'] >= 4]\n",
    "\n",
    "# Группируем фильмы по пользователям, формируя транзакции\n",
    "transactions = df_filtered.groupby('user_id')['movie_id'].apply(list).tolist()\n",
    "\n",
    "# Применение алгоритма Apriori с заданными параметрами\n",
    "rules = apriori(transactions, min_support=0.2, min_confidence=0.3, min_lift=2, min_length=2)\n",
    "\n",
    "# Преобразование результата в список\n",
    "rules_list = list(rules)\n",
    "\n",
    "# Извлечение всех фильмов из правил\n",
    "films = []\n",
    "for rule in rules_list:\n",
    "    for stat in rule.ordered_statistics:\n",
    "        films.extend(list(stat.items_base))\n",
    "        films.extend(list(stat.items_add))\n",
    "\n",
    "# Подсчет частоты появления каждого фильма\n",
    "film_counter = Counter(films)\n",
    "\n",
    "# Поиск фильма, который встречается чаще всего\n",
    "most_common_film = film_counter.most_common(1)[0]  # Получаем tuple (film_id, frequency)\n",
    "\n",
    "# Вывод результата\n",
    "print(f\"ID фильма, который чаще всего встречается в правилах: {most_common_film[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
